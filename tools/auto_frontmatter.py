#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
from pathlib import Path
from datetime import datetime

def has_complete_frontmatter(content):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²æœ‰å®Œæ•´çš„frontmatter"""
    if not content.strip().startswith('---'):
        return False
    
    parts = content.split('---', 2)
    if len(parts) < 3:
        return False
    
    frontmatter = parts[1].strip()
    # æ£€æŸ¥æ˜¯å¦åŒ…å«åŸºæœ¬å¿…éœ€å­—æ®µ
    has_title = re.search(r'title:\s*["\']?[^"\'\n]+["\']?', frontmatter)
    has_date = re.search(r'date:\s*\d{4}-\d{2}-\d{2}', frontmatter)
    
    return bool(has_title and has_date)

def extract_title_from_filename(filename):
    """ä»æ–‡ä»¶åæå–æ ‡é¢˜"""
    # ç§»é™¤æ—¥æœŸå‰ç¼€å’Œæ‰©å±•å
    title = re.sub(r'^\d{4}-\d{2}-\d{2}-', '', filename)
    title = re.sub(r'\.md$', '', title)
    # æ›¿æ¢è¿å­—ç¬¦å’Œä¸‹åˆ’çº¿ä¸ºç©ºæ ¼
    title = title.replace('-', ' ').replace('_', ' ')
    return title.strip()

def extract_title_from_content(content):
    """ä»å†…å®¹ä¸­æå–æ ‡é¢˜"""
    lines = content.strip().split('\n')
    for line in lines:
        line = line.strip()
        if line.startswith('# '):
            return line[2:].strip()
        elif line.startswith('## '):
            return line[3:].strip()
        elif line.startswith('### '):
            return line[4:].strip()
    return None

def determine_category_from_path(filepath):
    """æ ¹æ®æ–‡ä»¶è·¯å¾„ç¡®å®šåˆ†ç±»"""
    path_parts = filepath.parts
    if len(path_parts) > 2:  # _posts/category/file.md
        category = path_parts[-2]  # å–ç›®å½•åä½œä¸ºåˆ†ç±»
        return [category]
    return []

def determine_tags_from_path_and_content(filepath, content):
    """æ ¹æ®è·¯å¾„å’Œå†…å®¹ç¡®å®šæ ‡ç­¾"""
    tags = []
    path_parts = filepath.parts
    
    # ä»è·¯å¾„ä¸­æå–æ ‡ç­¾
    for part in path_parts:
        if part.lower() in ['algorithm', 'dp', 'java', 'python', 'git', 'llm', 'ml', 'marl']:
            tags.append(part.lower())
    
    # ä»å†…å®¹ä¸­æå–æ ‡ç­¾
    content_lower = content.lower()
    if 'algorithm' in content_lower or 'ç®—æ³•' in content:
        tags.append('algorithm')
    if 'java' in content_lower:
        tags.append('java')
    if 'python' in content_lower:
        tags.append('python')
    if 'machine learning' in content_lower or 'ml' in content_lower:
        tags.append('ml')
    if 'deep learning' in content_lower or 'dl' in content_lower:
        tags.append('dl')
    
    return list(set(tags))  # å»é‡

def extract_date_from_filename(filename):
    """ä»æ–‡ä»¶åæå–æ—¥æœŸ"""
    match = re.match(r'^(\d{4}-\d{2}-\d{2})', filename)
    if match:
        return match.group(1) + ' 03:39:16 +0800'
    return datetime.now().strftime('%Y-%m-%d %H:%M:%S +0800')



def generate_frontmatter(title, date, categories, tags, has_math=False):
    """ç”Ÿæˆæ ‡å‡†çš„frontmatter"""
    frontmatter = f"""---
title: "{title}"
date: {date}"""
    
    if categories:
        if len(categories) == 1:
            frontmatter += f"\ncategories: [{categories[0]}]"
        else:
            frontmatter += f"\ncategories:\n"
            for cat in categories:
                frontmatter += f"    - {cat}\n"
    
    if tags:
        frontmatter += f"\ntags: {tags}"
    
    if has_math:
        frontmatter += f"\nmath: true"
    
    frontmatter += f"\n---"
    
    return frontmatter

def process_file(filepath):
    """å¤„ç†å•ä¸ªmarkdownæ–‡ä»¶"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
    except UnicodeDecodeError:
        print(f"âš ï¸  æ— æ³•è¯»å–æ–‡ä»¶ {filepath} (ç¼–ç é—®é¢˜)")
        return False
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰å®Œæ•´frontmatter
    if has_complete_frontmatter(content):
        print(f"âœ… è·³è¿‡ {filepath.name} (å·²æœ‰å®Œæ•´frontmatter)")
        return False
    
    print(f"ğŸ”„ å¤„ç† {filepath.name}")
    
    # æå–ç°æœ‰å†…å®¹ï¼ˆç§»é™¤ä¸å®Œæ•´çš„frontmatterï¼‰
    if content.strip().startswith('---'):
        parts = content.split('---', 2)
        if len(parts) >= 3:
            main_content = parts[2].strip()
        else:
            main_content = content.strip()
    else:
        main_content = content.strip()
    
    filename = filepath.name
    
    # ç¡®å®šæ ‡é¢˜
    title = extract_title_from_content(main_content)
    if not title:
        title = extract_title_from_filename(filename)
    
    # ç¡®å®šæ—¥æœŸ
    date = extract_date_from_filename(filename)
    
    # ç¡®å®šåˆ†ç±»
    categories = determine_category_from_path(filepath)
    
    # ç¡®å®šæ ‡ç­¾
    tags = determine_tags_from_path_and_content(filepath, main_content)
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­¦å…¬å¼
    has_math = '$' in main_content or '\\(' in main_content or '\\[' in main_content
    
    # ç”Ÿæˆæ–°çš„frontmatter
    new_frontmatter = generate_frontmatter(title, date, categories, tags, has_math)
    
    # ç»„åˆæœ€ç»ˆå†…å®¹
    final_content = new_frontmatter + '\n\n' + main_content
    
    # å†™å›æ–‡ä»¶
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(final_content)
        print(f"âœ… å·²æ·»åŠ frontmatteråˆ° {filepath.name}")
        return True
    except Exception as e:
        print(f"âŒ å†™å…¥æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    posts_dir = Path('_posts')
    
    if not posts_dir.exists():
        print("âŒ é”™è¯¯: _postsç›®å½•ä¸å­˜åœ¨")
        return
    
    # æ‰¾åˆ°æ‰€æœ‰.mdæ–‡ä»¶
    md_files = list(posts_dir.rglob('*.md'))
    
    print(f"ğŸ“ æ‰¾åˆ° {len(md_files)} ä¸ªmarkdownæ–‡ä»¶")
    print("-" * 50)
    
    processed_count = 0
    for filepath in md_files:
        if filepath.name.startswith('.'):  # è·³è¿‡éšè—æ–‡ä»¶
            continue
        if process_file(filepath):
            processed_count += 1
    
    print("-" * 50)
    print(f"ğŸ‰ å¤„ç†å®Œæˆ! å…±ä¸º {processed_count} ä¸ªæ–‡ä»¶æ·»åŠ äº†frontmatter")
    
    if processed_count == 0:
        print("ğŸ’¡ æ‰€æœ‰æ–‡ä»¶éƒ½å·²æœ‰å®Œæ•´çš„frontmatterï¼Œæ— éœ€å¤„ç†")

if __name__ == "__main__":
    main() 